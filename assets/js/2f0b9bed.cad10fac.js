"use strict";(self.webpackChunkxef_website=self.webpackChunkxef_website||[]).push([[206],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>h});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(n),d=o,h=p["".concat(s,".").concat(d)]||p[d]||m[d]||r;return n?a.createElement(h,i(i({ref:t},c),{},{components:n})):a.createElement(h,i({ref:t},c))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:o,i[1]=l;for(var u=2;u<r;u++)i[u]=n[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},85162:(e,t,n)=>{n.d(t,{Z:()=>i});var a=n(67294),o=n(86010);const r={tabItem:"tabItem_Ymn6"};function i(e){let{children:t,hidden:n,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,o.Z)(r.tabItem,i),hidden:n},t)}},74866:(e,t,n)=>{n.d(t,{Z:()=>x});var a=n(87462),o=n(67294),r=n(86010),i=n(12466),l=n(16550),s=n(91980),u=n(67392),c=n(50012);function p(e){return function(e){return o.Children.map(e,(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:o}}=e;return{value:t,label:n,attributes:a,default:o}}))}function m(e){const{values:t,children:n}=e;return(0,o.useMemo)((()=>{const e=t??p(n);return function(e){const t=(0,u.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function d(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function h(e){let{queryString:t=!1,groupId:n}=e;const a=(0,l.k6)(),r=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,s._X)(r),(0,o.useCallback)((e=>{if(!r)return;const t=new URLSearchParams(a.location.search);t.set(r,e),a.replace({...a.location,search:t.toString()})}),[r,a])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,r=m(e),[i,l]=(0,o.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!d({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:r}))),[s,u]=h({queryString:n,groupId:a}),[p,f]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,r]=(0,c.Nk)(n);return[a,(0,o.useCallback)((e=>{n&&r.set(e)}),[n,r])]}({groupId:a}),b=(()=>{const e=s??p;return d({value:e,tabValues:r})?e:null})();(0,o.useLayoutEffect)((()=>{b&&l(b)}),[b]);return{selectedValue:i,selectValue:(0,o.useCallback)((e=>{if(!d({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),f(e)}),[u,f,r]),tabValues:r}}var b=n(72389);const k={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function g(e){let{className:t,block:n,selectedValue:l,selectValue:s,tabValues:u}=e;const c=[],{blockElementScrollPositionUntilNextRender:p}=(0,i.o5)(),m=e=>{const t=e.currentTarget,n=c.indexOf(t),a=u[n].value;a!==l&&(p(t),s(a))},d=e=>{let t=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const n=c.indexOf(e.currentTarget)+1;t=c[n]??c[0];break}case"ArrowLeft":{const n=c.indexOf(e.currentTarget)-1;t=c[n]??c[c.length-1];break}}t?.focus()};return o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":n},t)},u.map((e=>{let{value:t,label:n,attributes:i}=e;return o.createElement("li",(0,a.Z)({role:"tab",tabIndex:l===t?0:-1,"aria-selected":l===t,key:t,ref:e=>c.push(e),onKeyDown:d,onClick:m},i,{className:(0,r.Z)("tabs__item",k.tabItem,i?.className,{"tabs__item--active":l===t})}),n??t)})))}function v(e){let{lazy:t,children:n,selectedValue:a}=e;const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===a));return e?(0,o.cloneElement)(e,{className:"margin-top--md"}):null}return o.createElement("div",{className:"margin-top--md"},r.map(((e,t)=>(0,o.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function y(e){const t=f(e);return o.createElement("div",{className:(0,r.Z)("tabs-container",k.tabList)},o.createElement(g,(0,a.Z)({},e,t)),o.createElement(v,(0,a.Z)({},e,t)))}function x(e){const t=(0,b.Z)();return o.createElement(y,(0,a.Z)({key:String(t)},e))}},21118:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>l,metadata:()=>u,toc:()=>p});var a=n(87462),o=(n(67294),n(3905)),r=n(74866),i=n(85162);const l={title:"Quickstart",description:"Get xef.ai up and running in Kotlin",sidebar_position:2,sidebar_custom_props:{icon:"icon-quickstart.svg"}},s='<decorated-text icon="icon-quickstart.svg" title="Quickstart" />',u={unversionedId:"learn/quickstart",id:"learn/quickstart",title:"Quickstart",description:"Get xef.ai up and running in Kotlin",source:"@site/content/docs/learn/quickstart.md",sourceDirName:"learn",slug:"/learn/quickstart",permalink:"/learn/quickstart",draft:!1,editUrl:"https://github.com/xebia-functional/xef-website/edit/main/content/docs/learn/quickstart.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"Quickstart",description:"Get xef.ai up and running in Kotlin",sidebar_position:2,sidebar_custom_props:{icon:"icon-quickstart.svg"}},sidebar:"learnSidebar",previous:{title:"Overview",permalink:"/learn/overview"},next:{title:"Integrations",permalink:"/learn/integrations/"}},c={},p=[{value:"Getting the libraries",id:"getting-the-libraries",level:2},{value:"Your first prompt",id:"your-first-prompt",level:2},{value:"Structure",id:"structure",level:2},{value:"@Description annotations",id:"description-annotations",level:2},{value:"Prompts",id:"prompts",level:2},{value:"Context",id:"context",level:2}],m={toc:p},d="wrapper";function h(e){let{components:t,...n}=e;return(0,o.kt)(d,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"decorated-text-iconicon-quickstartsvg-titlequickstart-"},(0,o.kt)("decorated-text",{icon:"icon-quickstart.svg",title:"Quickstart"})),(0,o.kt)("h2",{id:"getting-the-libraries"},"Getting the libraries"),(0,o.kt)("p",null,"Libraries are published in Maven Central. You may need to  add that repository explicitly\nin your build, if you haven't done it before. Then add the library in the usual way."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'repositories {\n    mavenCentral()\n}\n\ndependencies {\n    implementation("com.xebia:xef-core:<version>")\n    implementation("com.xebia:xef-openai:<version>")\n}\n')),(0,o.kt)("p",null,"We publish all libraries at once under the same version, so\n",(0,o.kt)("a",{parentName:"p",href:"https://docs.gradle.org/current/userguide/platforms.html#sec:sharing-catalogs"},"version catalogs"),"\ncould be useful."),(0,o.kt)("p",null,"By default, the ",(0,o.kt)("inlineCode",{parentName:"p"},"OpenAI.conversation")," block connects to ",(0,o.kt)("a",{parentName:"p",href:"https://platform.openai.com/"},"OpenAI"),".\nTo use their services you should provide the corresponding API key in the ",(0,o.kt)("inlineCode",{parentName:"p"},"OPENAI_TOKEN"),"\nenvironment variable, and have enough credits."),(0,o.kt)(r.Z,{mdxType:"Tabs"},(0,o.kt)(i.Z,{value:"gradle",label:"Gradle",default:!0,mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"env OPENAI_TOKEN=<your-token> <gradle-command>\n"))),(0,o.kt)(i.Z,{value:"intellij",label:"IntelliJ",mdxType:"TabItem"},(0,o.kt)("p",null,"Set the environment variable ",(0,o.kt)("inlineCode",{parentName:"p"},"OPENAI_TOKEN=xxx")," in the properties."))),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"This library may transmit source code and potentially user input data to third-party services as part of its functionality.\nDevelopers integrating this library into their applications should be aware of this behavior and take necessary precautions to ensure that sensitive data is not inadvertently transmitted.\nRead our ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/xebia-functional/xef#%EF%B8%8F-data-transmission-disclosure"},(0,o.kt)("em",{parentName:"a"},"Data Transmission Disclosure"))," for further information.")),(0,o.kt)("h2",{id:"your-first-prompt"},"Your first prompt"),(0,o.kt)("p",null,"After adding the library to your project you get access to the ",(0,o.kt)("inlineCode",{parentName:"p"},"conversation")," function, which is your port of entry to the modern AI world.\nInside of it, you can ",(0,o.kt)("em",{parentName:"p"},"prompt")," for information, which means posing the question to an LLM\n(Large Language Model). The easiest way is to just get the information back as a string."),(0,o.kt)(r.Z,{mdxType:"Tabs"},(0,o.kt)(i.Z,{value:"code",label:"Code",default:!0,mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'import com.xebia.functional.xef.conversation.llm.openai.OpenAI\nimport com.xebia.functional.xef.conversation.llm.openai.promptMessage\n\nsuspend fun main() {\n  println(books("Artificial Intelligence"))\n}\n\nsuspend fun books(topic: String): String = OpenAI.conversation {\n  promptMessage("Give me a selection of books about $topic")\n}\n'))),(0,o.kt)(i.Z,{value:"output",label:"Output",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'Here are some books about Artificial Intelligence:\n\n1. "Superintelligence: Paths, Dangers, Strategies" by Nick Bostrom\n2. "Artificial Intelligence: A Modern Approach" by Stuart Russell and Peter Norvig\n3. "Life 3.0: Being Human in the Age of Artificial Intelligence" by Max Tegmark\n4. "The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World" by Pedro Domingos\n5. "Human Compatible: Artificial Intelligence and the Problem of Control" by Stuart Russell\n6. "AI Superpowers: China, Silicon Valley, and the New World Order" by Kai-Fu Lee\n7. "The Singularity Is Near: When Humans Transcend Biology" by Ray Kurzweil\n8. "Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n9. "Artificial Intelligence: Foundations of Computational Agents" by David L. Poole and Alan K. Mackworth\n10. "Machines of Loving Grace: The Quest for Common Ground Between Humans and Robots" by John Markoff\n\nThese books cover a wide range of topics related to Artificial Intelligence, including its history, potential risks, ethical considerations, and its impact on society.\n')))),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"books")," function above uses the ",(0,o.kt)("inlineCode",{parentName:"p"},"conversation")," function to connect to OpenAI,\nand then uses the ",(0,o.kt)("inlineCode",{parentName:"p"},"promptMessage")," function to ask for a selection of books about a given topic.\nThe result is a string with the answer from the LLM.",(0,o.kt)("br",null)),(0,o.kt)("h2",{id:"structure"},"Structure"),(0,o.kt)("p",null,"The output from the ",(0,o.kt)("inlineCode",{parentName:"p"},"books")," function above may be hard to parse back from the\nstrings we obtain. Fortunately, you can also ask xef.ai to give you back the information\nusing a ",(0,o.kt)("em",{parentName:"p"},"custom type"),"."),(0,o.kt)("p",null,"The library takes care of instructing the LLM on building such\na structure, and deserialize the result back for you."),(0,o.kt)(r.Z,{mdxType:"Tabs"},(0,o.kt)(i.Z,{value:"code",label:"Code",default:!0,mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'import com.xebia.functional.xef.conversation.llm.openai.OpenAI\nimport com.xebia.functional.xef.conversation.llm.openai.prompt\nimport kotlinx.serialization.Serializable\n\nsuspend fun main() {\n  val result = books("Heavy Metal")\n  result.books.forEach { println("""\n    Title: ${it.title}\n    Author: ${it.author}\n  """.trimIndent()) }\n}\n\n@Serializable\ndata class Books(val books: List<Book>)\n\n@Serializable\ndata class Book(val title: String, val author: String)\n\nsuspend fun books(topic: String): Books = OpenAI.conversation {\n  prompt("Give me a selection of books about $topic")\n}\n'))),(0,o.kt)(i.Z,{value:"output",label:"Output",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"Title: Lords of Chaos: The Bloody Rise of the Satanic Metal Underground\nAuthor: Michael Moynihan\n\nTitle: Choosing Death: The Improbable History of Death Metal and Grindcore\nAuthor: Albert Mudrian\n\nTitle: Sound of the Beast: The Complete Headbanging History of Heavy Metal\nAuthor: Ian Christe\n\nTitle: Black Metal: Evolution of the Cult\nAuthor: Dayal Patterson\n\nTitle: Metallica: Enter Night\nAuthor: Mick Wall\n")))),(0,o.kt)("p",null,"xef.ai reuses ",(0,o.kt)("a",{parentName:"p",href:"https://kotlinlang.org/docs/serialization.html"},"Kotlin's common serialization"),",\nwhich requires adding the ",(0,o.kt)("inlineCode",{parentName:"p"},"kotlinx.serialization")," plug-in to your build, and mark each\nclass as ",(0,o.kt)("inlineCode",{parentName:"p"},"@Serializable"),". The LLM is usually able to detect which kind of information should\ngo on each field based on its name (like ",(0,o.kt)("inlineCode",{parentName:"p"},"title")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"author")," above). For those cases where the LLM is not able to infer the type, you can use the ",(0,o.kt)("inlineCode",{parentName:"p"},"@Description")," annotation:"),(0,o.kt)("h2",{id:"description-annotations"},"@Description annotations"),(0,o.kt)(r.Z,{mdxType:"Tabs"},(0,o.kt)(i.Z,{value:"code",label:"Code",default:!0,mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'import com.xebia.functional.xef.conversation.Description\nimport com.xebia.functional.xef.conversation.llm.openai.OpenAI\nimport com.xebia.functional.xef.conversation.llm.openai.prompt\nimport kotlinx.serialization.Serializable\n\nsuspend fun main() {\n  val result = books("Artificial Intelligence")\n  result.books.forEach { println("""\n    Title: ${it.title}\n    Author: ${it.author}\n    Summary: ${it.summary}\n  """.trimIndent()) }\n}\n\n@Serializable\n@Description("A list of books")\ndata class Books(\n  @Description("The list of books")\n  val books: List<Book>\n)\n\n@Serializable\n@Description("A book")\ndata class Book(\n  @Description("The title of the book")\n  val title: String,\n  @Description("The author of the book")\n  val author: String,\n  @Description("A 20 word summary of the book")\n  val summary: String\n)\n\nsuspend fun books(topic: String): Books = OpenAI.conversation {\n  prompt("Give me a selection of books about $topic")\n}\n'))),(0,o.kt)(i.Z,{value:"output",label:"Output",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"Title: Artificial Intelligence: A Modern Approach\nAuthor: Stuart Russell, Peter Norvig\nSummary: This book provides a comprehensive introduction to the field of artificial intelligence, covering topics such as problem-solving, knowledge representation, and machine learning.\n\nTitle: Superintelligence: Paths, Dangers, Strategies\nAuthor: Nick Bostrom\nSummary: In this thought-provoking book, Nick Bostrom explores the potential risks and benefits of developing superintelligent machines and discusses strategies for ensuring a positive outcome.\n\nTitle: Machine Learning: A Probabilistic Perspective\nAuthor: Kevin P. Murphy\nSummary: This book offers a comprehensive introduction to machine learning, with a focus on probabilistic models and their applications in various domains.\n\nTitle: Deep Learning\nAuthor: Ian Goodfellow, Yoshua Bengio, Aaron Courville\nSummary: Deep Learning provides a comprehensive introduction to deep learning methods and architectures, covering topics such as neural networks, convolutional networks, and recurrent networks.\n\nTitle: The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World\nAuthor: Pedro Domingos\nSummary: In this book, Pedro Domingos explores the five tribes of machine learning and argues that the ultimate learning algorithm should combine the strengths of all these approaches.\n")))),(0,o.kt)("p",null,"All the types and properties annotated with ",(0,o.kt)("inlineCode",{parentName:"p"},"@Description")," will be used to build the\njson schema ",(0,o.kt)("inlineCode",{parentName:"p"},"description")," fields used for the LLM to reply with the right format and data\nin order to deserialize the result back. "),(0,o.kt)("h2",{id:"prompts"},"Prompts"),(0,o.kt)("p",null,"The function ",(0,o.kt)("inlineCode",{parentName:"p"},"books")," uses naive string interpolation to make the topic part of the question\nto the LLM. As the prompt gets bigger, though, you may want to break it into smaller parts.\nWe use the ",(0,o.kt)("a",{parentName:"p",href:"https://kotlinlang.org/docs/type-safe-builders.html"},"builder pattern")," to include messages and\nother prompts which get built before the chat completions endpoint."),(0,o.kt)(r.Z,{mdxType:"Tabs"},(0,o.kt)(i.Z,{value:"code",label:"Code",default:!0,mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'import com.xebia.functional.xef.conversation.Conversation\nimport com.xebia.functional.xef.conversation.llm.openai.OpenAI\nimport com.xebia.functional.xef.conversation.llm.openai.prompt\nimport com.xebia.functional.xef.prompt.Prompt\nimport com.xebia.functional.xef.prompt.templates.system\nimport com.xebia.functional.xef.prompt.templates.assistant\nimport com.xebia.functional.xef.prompt.templates.user\nimport kotlinx.serialization.Serializable\n\nsuspend fun main() {\n  val result = OpenAI.conversation {\n    books("Cooking")\n  }\n\n  result.books.forEach { println("""\n    Title: ${it.title}\n    Author: ${it.author}\n  """.trimIndent()) }\n}\n\n@Serializable\ndata class Books(val books: List<Book>)\n\n@Serializable\ndata class Book(val title: String, val author: String)\n\nsuspend fun Conversation.books(topic: String): Books {\n  val myCustomPrompt = Prompt {\n    +system("You are an assistant in charge of providing a selection of books about topics provided")\n    +assistant("I will provide relevant suggestions of books and follow the instructions closely.")\n    +user("Give me a selection of books about $topic")\n  }\n\n  return prompt(myCustomPrompt)\n}\n'))),(0,o.kt)(i.Z,{value:"output",label:"Output",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"Title: Salt, Fat, Acid, Heat: Mastering the Elements of Good Cooking\nAuthor: Samin Nosrat\n\nTitle: The Joy of Cooking\nAuthor: Irma S. Rombauer\n\nTitle: The Food Lab: Better Home Cooking Through Science\nAuthor: J. Kenji L\xf3pez-Alt\n\nTitle: Cooking for Geeks: Real Science, Great Hacks, and Good Food\nAuthor: Jeff Potter\n\nTitle: The Flavor Bible: The Essential Guide to Culinary Creativity, Based on the Wisdom of America's Most Imaginative Chefs\nAuthor: Karen Page and Andrew Dornenburg\n")))),(0,o.kt)("p",null,"This style of prompting is more effective than simple strings messages as it describes a scene of how the LLM\nshould behave and reply. We use different roles for each message constructed with the ",(0,o.kt)("inlineCode",{parentName:"p"},"Prompt")," builder."),(0,o.kt)("p",null,"In a larger AI application it's common to end up with quite some template for prompts.\nOnline material like ",(0,o.kt)("a",{parentName:"p",href:"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/"},"this course"),"\nand ",(0,o.kt)("a",{parentName:"p",href:"https://learnprompting.org/docs/intro"},"this tutorial")," explain some of the most important patterns,\nsome of them readily available in xef.ai."),(0,o.kt)("h2",{id:"context"},"Context"),(0,o.kt)("p",null,"LLMs have knowledge about a broad variety of topics. But by construction they are not able\nto respond to questions about information not available in their training set. However, you\noften want to supplement the LLM with more data:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Transient information referring to the current moment, like the current weather, or\nthe trends in the stock market in the past 10 days."),(0,o.kt)("li",{parentName:"ul"},"Non-public information, for example for summarizing a piece of text you're creating\nwithin you organization.")),(0,o.kt)("p",null,"These additional pieces of information are called the ",(0,o.kt)("em",{parentName:"p"},"context")," in xef.ai, and are attached\nto every question to the LLM. Although you can add arbitrary strings to the context at any\npoint, the most common mode of usage is using an ",(0,o.kt)("em",{parentName:"p"},"agent")," to consult an external service,\nand make its response part of the context. One such agent is ",(0,o.kt)("inlineCode",{parentName:"p"},"Search"),", which uses a web\nsearch service to enrich that context."),(0,o.kt)(r.Z,{mdxType:"Tabs"},(0,o.kt)(i.Z,{value:"code",label:"Code",default:!0,mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'import com.xebia.functional.xef.conversation.llm.openai.OpenAI\nimport com.xebia.functional.xef.conversation.llm.openai.promptMessage\nimport com.xebia.functional.xef.prompt.Prompt\nimport com.xebia.functional.xef.reasoning.serpapi.Search\n\nsuspend fun main() {\n  val question = Prompt("Knowing this forecast, what clothes do you recommend I should wear?")\n\n  OpenAI.conversation {\n    val search = Search(OpenAI.fromEnvironment().DEFAULT_CHAT, this)\n    addContext(search("Weather in C\xe1diz, Spain"))\n    val answer = promptMessage(question)\n    println(answer)\n  }\n}\n')))),(0,o.kt)("p",null,"To execute the code you need to add the ",(0,o.kt)("inlineCode",{parentName:"p"},"xef-reasoning")," library to your project,\nand provide the ",(0,o.kt)("inlineCode",{parentName:"p"},"SERPAPI_TOKEN")," environment variable with a valid token from ",(0,o.kt)("a",{parentName:"p",href:"https://serpapi.com/"},"SerpApi"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'dependencies {\n  implementation("com.xebia:xef-reasoning:<version>")\n}\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"env SERP_API_KEY=<your-api-key>\n")),(0,o.kt)("admonition",{title:"Better vector stores",type:"note"},(0,o.kt)("p",{parentName:"admonition"},"The underlying mechanism of the context is a ",(0,o.kt)("em",{parentName:"p"},"vector store"),", a data structure which\nsaves a set of strings, and is able to find those similar to another given one.\nBy default xef.ai uses an ",(0,o.kt)("em",{parentName:"p"},"in-memory")," vector store, since it provides maximum\ncompatibility across platforms. However, if you foresee your context growing above\nthe hundreds of elements, you may consider switching to another alternative, like\nLucene or PostgreSQL also supported by xef.")))}h.isMDXComponent=!0}}]);